{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ES client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "#es = Elasticsearch()\n",
    "es = Elasticsearch(hosts= [{\n",
    "  'host': 'localhost',\n",
    "  'port': 9200,\n",
    "  'headers': {\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "  }\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"name\" : \"GEdcTh3\",\\n  \"cluster_name\" : \"elasticsearch\",\\n  \"cluster_uuid\" : \"8Du4O1XkQ6qY2mLer7ohgA\",\\n  \"version\" : {\\n    \"number\" : \"6.6.1\",\\n    \"build_flavor\" : \"default\",\\n    \"build_type\" : \"deb\",\\n    \"build_hash\" : \"1fd8f69\",\\n    \"build_date\" : \"2019-02-13T17:10:04.160291Z\",\\n    \"build_snapshot\" : false,\\n    \"lucene_version\" : \"7.6.0\",\\n    \"minimum_wire_compatibility_version\" : \"5.6.0\",\\n    \"minimum_index_compatibility_version\" : \"5.0.0\"\\n  },\\n  \"tagline\" : \"You Know, for Search\"\\n}\\n'\n",
      "{'_primary_term': 1, '_index': 'test-indexw', '_type': 'tweet', '_id': '1', '_version': 1, 'result': 'created', '_seq_no': 0, '_shards': {'successful': 1, 'failed': 0, 'total': 2}}\n"
     ]
    }
   ],
   "source": [
    "es.indices.create(index='test-indexw', \n",
    "                  ignore=400)\n",
    "res = requests.get('http://localhost:9200')\n",
    "print(res.content)\n",
    "\n",
    "doc = {\n",
    "    'author': 'kimchy',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool.',\n",
    "    'timestamp': datetime.now(),\n",
    "}\n",
    "\n",
    "es.count(index='test-indexw')\n",
    "\n",
    "res = es.index(index=\"test-indexw\", doc_type='tweet', id=1, body=doc)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresh and count index elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'skipped': 0, 'successful': 5, 'total': 5},\n",
       " 'count': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.refresh(index=\"test-indexw\")\n",
    "es.count(index='test-indexw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search elements with query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 Hits:\n",
      "2019-02-26T10:43:26.929426 kimchy: Elasticsearch: cool. bonsai cool.\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index=\"test-indexw\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='test-indexw', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case: Index movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    [item for sublist in l for item in sublist]\n",
    "\n",
    "def simplerExplain(explainJson, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
    "    #print json.dumps(explainJson, indent=True)\n",
    "    if 'details' in explainJson:\n",
    "        for detail in explainJson['details']:\n",
    "            result += simplerExplain(detail, depth=depth+1)\n",
    "    return result\n",
    "\n",
    "def extract():\n",
    "    f = open('tmdb.json')\n",
    "    if f:\n",
    "         return json.loads(f.read());        \n",
    "    return {}\n",
    "\n",
    "\n",
    "def timer(start,end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "def reindex_seq(analysisSettings={}, mappingSettings={}, movieDict={}):\n",
    "    '''Sequencialy index new values'''\n",
    "    bulkMovies =  ({'_index':'test-movie','doc':movieDict[i], '_type':'movie', '_id':i} for i in movieDict.keys() )\n",
    "    #helpers.bulk(es,bulkMovies)\n",
    "    \n",
    "    for i in bulkMovies:\n",
    "        es.index(index=\"test-movie\", doc_type='movie', \n",
    "                 id=i['_id'], body=i['doc'])\n",
    "        \n",
    "    print (\"indexing...\")\n",
    "    \n",
    "def reindex_chunk(index, chunk_size, Settings={},\n",
    "                       movieDict={}):\n",
    "    \"\"\"Batch insert new values on index for faster creation\"\"\"\n",
    "    print(\"Delete index\")\n",
    "    es.indices.delete(index=index, ignore=400)\n",
    "    es.indices.create(index=index, ignore=400, body=Settings)\n",
    "    bulkMovies =  ({'_index':index,'doc':movieDict[i], '_type':'movie', '_id':i} for i in movieDict.keys() )\n",
    "    print(\"Indexing\")\n",
    "    for ok, response in helpers.streaming_bulk(es, actions = bulkMovies, chunk_size=chunk_size, max_retries=10):\n",
    "        if not ok:\n",
    "            # failure inserting\n",
    "            print (response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#index time settings analyzer (converts to tokens)\n",
    "# Analyzers and mappers !\n",
    "\n",
    "analyze_settings = {\n",
    "     \"analyzer\": {\n",
    "       \"movies_analyzer\": {\n",
    "         \"type\": \"standard\",\n",
    "         \"stopwords\": \"_english_\",\n",
    "            \n",
    "       }\n",
    "     }\n",
    "   ,\n",
    "\n",
    "  \"mappings\": {\n",
    "    \"movie\": { \n",
    "      \"properties\": {\n",
    "        \"title\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "        \"overview\": { \"type\": \"text\", \"analyzer\": \"english\"}\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \n",
    "}\n",
    "\n",
    "settings_index = { #A\n",
    "        \"settings\": {\n",
    "                \"analysis\" : analyze_settings, #C\n",
    "            }}\n",
    "\n",
    "json.dumps(settings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this setting have a filter with tstemmer for english words\n",
    "analyze_settings = {\n",
    "     \"analyzer\": {\n",
    "       \"movies_analyzer\": {\n",
    "         \"type\": \"standard\",\n",
    "         \"stopwords\": \"_english_\",\n",
    "         \"filter\" : [\"lowercase\", \"my_stemmer\"]\n",
    "       }\n",
    "     }\n",
    "    ,\n",
    "    \"filter\" : {\n",
    "                \"my_stemmer\" : {\n",
    "                    \"type\" : \"stemmer\",\n",
    "                    \"name\" : \"english\"\n",
    "                }\n",
    "            },\n",
    "\n",
    "  \"mappings\": {\n",
    "    \"movie\": { \n",
    "      \"properties\": {\n",
    "        \"title\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "        \"overview\": { \"type\": \"text\", \"analyzer\": \"english\"}\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \n",
    "}\n",
    "\n",
    "settings_index = { #A\n",
    "        \"settings\": {\n",
    "                \"analysis\" : analyze_settings, #C\n",
    "            }}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this setting have a filter with tstemmer for english words\n",
    "analyze_settings ={ \"mappings\": {\n",
    "    \"movie\": {\n",
    "            \"properties\": {\n",
    "               \"title\": { #A\n",
    "                   \"type\": \"string\",\n",
    "                   \"analyzer\": \"english\"\n",
    "               },\n",
    "            \"overview\": {\n",
    "                   \"type\": \"string\",\n",
    "                   \"analyzer\": \"english\"\n",
    "               }\n",
    "            }\n",
    "       }\n",
    "}\n",
    "}\n",
    "settings_index = { #A\n",
    "        \"settings\": {\n",
    "                \"analysis\" : analyze_settings, #C\n",
    "            }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete index\n",
      "Indexing\n",
      "00:00:01.69\n",
      "{'_shards': {'successful': 5, 'failed': 0, 'total': 5, 'skipped': 0}, 'count': 3051}\n"
     ]
    }
   ],
   "source": [
    "movieDict = extract()\n",
    "\n",
    "t1 = time.time()\n",
    "reindex_chunk(index='test-movie', chunk_size=500, movieDict=movieDict, Settings=settings_index)\n",
    "t2 = time.time()\n",
    "timer(t1, t2)\n",
    "\n",
    "es.indices.refresh(index=\"test-movie\")\n",
    "print(es.count(index='test-movie'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.522362 11260 Meet Dave\n",
      "1 8.215713 2300 Space Jam\n",
      "2 7.863373 38365 Grown Ups\n",
      "3 7.842091 13260 Semi-Pro\n",
      "4 7.292982 20856 Aliens in the Attic\n",
      "5 7.14475 679 Aliens\n",
      "6 7.0154967 7459 Speed Racer\n",
      "7 6.710354 8078 Alien: Resurrection\n",
      "8 6.5932465 80035 The Watch\n",
      "9 6.3094597 888 The Flintstones\n"
     ]
    }
   ],
   "source": [
    "def search(query, index, n_hits=10, explain=False):\n",
    "    searchHits = es.search(index=index, doc_type='movie', body= query, size=n_hits, explain=explain)\n",
    "    for idx, hit in enumerate(searchHits['hits']['hits']):\n",
    "        print(idx, hit['_score'], hit['_id'], hit['_source']['doc']['title'])\n",
    "    return searchHits\n",
    "\n",
    "fieldsSearch = ['doc.title', 'doc.overview']# Limit search on this fields  'doc.genres']\n",
    "usersSearch = 'basketball with cartoon aliens'\n",
    "\n",
    "search_object = {'_source':[],#fieldsSearch, \n",
    "                 'query': {\n",
    "            'multi_match': { \n",
    "                'query': usersSearch,\n",
    "                'fields': ['doc.title^1', 'doc.overview'] #if we take out 10 it will return space jam as second\n",
    "            },\n",
    "        }}\n",
    "\n",
    "hits = search(query=search_object, index = 'test-movie', explain=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': '10882', '_type': 'movie'}, {'_id': '10530', '_type': 'movie'}, {'_id': '16781', '_type': 'movie'}, {'_id': '11675', '_type': 'movie'}, {'_id': '9296', '_type': 'movie'}, {'_id': '13596', '_type': 'movie'}, {'_id': '144336', '_type': 'movie'}, {'_id': '582', '_type': 'movie'}, {'_id': '8012', '_type': 'movie'}, {'_id': '105', '_type': 'movie'}]\n",
      "One hit:  {'_id': '10882', '_type': 'movie'}\n"
     ]
    }
   ],
   "source": [
    "# returns first 10 hits in a dictionary, here we use filter_path to filter \n",
    "hits = es.search(index='test-movie', filter_path=['hits.hits._id', 'hits.hits._type'])\n",
    "\n",
    "print(hits['hits']['hits']) # list of dictionarys)\n",
    "print('One hit: ',hits['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['doc'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['hits']['hits'][0]['_source'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['video', 'homepage', 'original_language', 'id', 'original_title', 'production_companies', 'vote_average', 'popularity', 'belongs_to_collection', 'poster_path', 'release_date', 'adult', 'budget', 'backdrop_path', 'status', 'spoken_languages', 'tagline', 'title', 'vote_count', 'overview', 'revenue', 'runtime', 'genres', 'directors', 'production_countries', 'cast', 'imdb_id'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns everything, matches with everything\n",
    "res = es.search(index='test-movie', filter_path=['hits.hits._*'])\n",
    "res['hits']['hits'][0]['_source']['doc'].keys()#['overview']# ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 10882 Sleeping Beauty\n",
      "Title:  Sleeping Beauty\n",
      "Genres:  [{'id': 16, 'name': 'Animation'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10749, 'name': 'Romance'}, {'id': 10751, 'name': 'Family'}]\n",
      "Overview:  A beautiful princess born in a faraway kingdom is destined by a terrible curse to prick her finger on the spindle of a spinning wheel and fall into a deep sleep that can only be awakened by true love's first kiss. Determined to protect her, her parents ask three fairies to raise her in hiding. But the evil Maleficent is just as determined to seal the princess's fate.\n"
     ]
    }
   ],
   "source": [
    "for idx, hit in enumerate(res['hits']['hits']):\n",
    "    print(idx, hit['_score'], hit['_id'], hit['_source']['doc']['title'])\n",
    "    break\n",
    "\n",
    "print(\"Title: \",res['hits']['hits'][0]['_source']['doc']['title'])\n",
    "print(\"Genres: \",res['hits']['hits'][0]['_source']['doc']['genres'])\n",
    "print(\"Overview: \",res['hits']['hits'][0]['_source']['doc']['overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CURL\n",
    "\n",
    "using CURL paste the following commands tu make requests to elastic search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Count results\n",
    "\n",
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/_count?pretty' -d '{\"query\": {\"multi_match\": {\"query\": \"aliens cartoon\",\"fields\": [\"doc.title\", \"doc.overview\"] }}}'\n",
    "\n",
    "# Search\n",
    "\n",
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/_search?pretty' -d '{\"query\": {\"multi_match\": {\"query\": \"aliens cartoon\",\"fields\": [\"doc.title\", \"doc.overview\"] }}}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analize results \n",
    "\n",
    "Without stopwords all words are taken into account. We need to set an analyzer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/_analyze?pretty' -d '{\"field\": \"title\", \"text\": \"basketball with cartoon aliens\"}'\n",
    "\n",
    "## The comman above returns:\n",
    "\n",
    "{\n",
    "  \"tokens\" : [\n",
    "    {\n",
    "      \"token\" : \"basketball\",\n",
    "      \"start_offset\" : 0,\n",
    "      \"end_offset\" : 10,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 0\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"with\",\n",
    "      \"start_offset\" : 11,\n",
    "      \"end_offset\" : 15,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 1\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"cartoon\",\n",
    "      \"start_offset\" : 16,\n",
    "      \"end_offset\" : 23,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 2\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"aliens\",\n",
    "      \"start_offset\" : 24,\n",
    "      \"end_offset\" : 30,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 3\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using english stop words 'with' is not a token anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords with custom analyzer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/_analyze?pretty' -d '{\"field\": \"title\", \"text\": \"basketball with cartoon aliens\", \"analyzer\":\"movies_analyzer\"}'\n",
    "\n",
    "{\n",
    "  \"tokens\" : [\n",
    "    {\n",
    "      \"token\" : \"basketball\",\n",
    "      \"start_offset\" : 0,\n",
    "      \"end_offset\" : 10,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 0\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"cartoon\",\n",
    "      \"start_offset\" : 16,\n",
    "      \"end_offset\" : 23,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 2\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"aliens\",\n",
    "      \"start_offset\" : 24,\n",
    "      \"end_offset\" : 30,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 3\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removes stopwords and uses stem porter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/_analyze?pretty' -d '{\"field\": \"title\", \"text\": \"basketball with cartoon aliens\", \"analyzer\":\"english\"}'\n",
    "\n",
    "{\n",
    "  \"tokens\" : [\n",
    "    {\n",
    "      \"token\" : \"basketbal\",\n",
    "      \"start_offset\" : 0,\n",
    "      \"end_offset\" : 10,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 0\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"cartoon\",\n",
    "      \"start_offset\" : 16,\n",
    "      \"end_offset\" : 23,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 2\n",
    "    },\n",
    "    {\n",
    "      \"token\" : \"alien\",\n",
    "      \"start_offset\" : 24,\n",
    "      \"end_offset\" : 30,\n",
    "      \"type\" : \"<ALPHANUM>\",\n",
    "      \"position\" : 3\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain search\n",
    "\n",
    "This is useful because we can see the score and also how the query is interpreted by elastic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_source': [],\n",
       " 'query': {'multi_match': {'fields': ['doc.title^1', 'doc.overview'],\n",
       "   'query': 'basketball with cartoon aliens'}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hit = es.search(index='test-movie', doc_type='movie', body= search_object, size=1, explain=True)\n",
    "#hit['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\"query\": {\"match\" : { \"doc.title\" : \"really powerful\"}}}\n",
    "\n",
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/_validate/query?explain' -d '{\"query\": {\"match\" : { \"doc.title\" : \"really powerful\"}}}'\n",
    "\n",
    "Returns\n",
    "\n",
    "{\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"valid\":true,\"explanations\":[{\"index\":\"test-movie\",\"valid\":true,\"explanation\":\"MatchNoDocsQuery(\\\"unmapped field [title]\\\")\"}]}wanda@wanda-X456UF:~/es-simple$ curl -H \"C1:9200/test-movie/_validate/query?explain' -d '{\"query\": {\"match\" : { \"doc.title\" : \"really powerful\"}}}'\n",
    "{\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"valid\":true,\"explanations\":[{\"index\":\"test-movie\",\"valid\":true,\"explanation\":\"doc.title:really doc.title:powerful\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-match"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl -H \"Content-Type: application/json;charset=UTF-8\" -XGET 'http://127.0.0.1:9200/test-movie/movie/_validate/query?explain' -d '{\"query\": {\"multi_match\": { \"query\": \"basketball with cartoon aliens\" , \"fields\": [\"doc.title^10\", \"doc.overview\"]}}}'\n",
    "\n",
    "\n",
    "{\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"valid\":true,\"explanations\":[{\"index\":\"test-movie\",\"valid\":true,\"explanation\":\"+MatchNoDocsQuery(\\\"Matching no documents because no terms present\\\") #*:*\"}]}wanda@wanda-1:9200/test-movie/movie/_validate/query?explain' -d '{\"query\": {\"multi_match\": { \"query\": \"basketball with cartoon aliens\" , \"fields\": [\"doc.title^10\", \"doc.overview\"]}}}'\n",
    "{\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"valid\":true,\"explanations\":[{\"index\":\"test-movie\",\"valid\":true,\"explanation\":\"+((doc.overview:basketball doc.overview:with doc.overview:cartoon doc.overview:aliens) | (doc.title:basketball doc.title:with doc.title:cartoon doc.title:aliens)^10.0) #*:*\"}]}wanda@wanda-X456UF:~/es1:9200/test-movie/movie/_validate/query?explain' -d '{\"query\": {\"multi_match\": { \"query\": \"basketball with cartoon aliens\" , \"fields\": [\"doc.title^10\", \"doc.overview\"]}}}'\n",
    "{\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"valid\":true,\"explanations\":[{\"index\":\"test-movie\",\"valid\":true,\"explanation\":\"+((doc.overview:basketball doc.overview:with doc.overview:cartoon doc.overview:aliens) | (doc.title:basketball doc.title:with doc.title:cartoon doc.title:aliens)^10.0) #*:*\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
